services:
  zookeeper:
    image: docker.io/bitnami/zookeeper
    volumes:
      - "zookeeper_data:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: docker.io/bitnami/kafka
    ports:
      - "9092:9092"
    volumes:
      - "kafka_data:/bitnami"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9093,EXTERNAL://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9093,EXTERNAL://kafka:9092
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      - zookeeper

  kafka-ui:
    image: provectuslabs/kafka-ui
    hostname: kafka-ui
    container_name: kafka_ui
    depends_on:
      - zookeeper
    ports:
      - "8080:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: kafkacluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"

  kafka-exporter:
    image: bitnami/kafka-exporter:latest
    ports:
      - "9308:9308"
    environment:
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_VERSION=2.7.0
    depends_on:
      - kafka

  spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
    volumes:
      - ./src/spark:/opt/bitnami/python/src/spark
    ports:
      - "7077:7077" # Spark Master
      - "8081:8080" # Spark Master WebUI
    hostname: spark-master

  spark-worker-a:
    image: bitnami/spark:latest
    hostname: spark-worker-a
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=4 # Number of cores to use
    depends_on:
      - spark-master

  spark-worker-b:
    image: bitnami/spark:latest
    hostname: spark-worker-b
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=4 # Number of cores to use
    depends_on:
      - spark-master

  crypto-producer:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile-crypto-producer
    depends_on:
      - kafka
      - zookeeper
    ports:
      - "8000:8000"

  spark-consumer:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile-spark-consumer
    hostname: spark-consumer
    environment:
      - VIRTUAL_ENV=/opt/bitnami/python
      - PROJECT_DIR=/app
    volumes:
      - ./src/spark:/app
    depends_on:
      - kafka
      - zookeeper
    ports:
      - "4040:4040" # Spark UI port
      - "8001:8001"
  
  crypto-processed-consumer:
    restart: always
    build:
      context: .
      dockerfile: Dockerfile-crypto-consumer
    depends_on:
      - spark-consumer
    ports:
      - "8002:8002"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - kafka-exporter
      - crypto-producer
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local
